{"componentChunkName":"component---src-templates-blog-post-js","path":"/como-criar-um-chatbot-usando-aprendizado-profundo-e-python/","result":{"data":{"site":{"siteMetadata":{"siteUrl":"https://thais-ribeiro-blog.netlify.com","githubUrl":"https://github.com/thaisribeiro/blog-thais"}},"mdx":{"fields":{"slug":"/como-criar-um-chatbot-usando-aprendizado-profundo-e-python/"},"timeToRead":5,"frontmatter":{"title":"Como criar um chatbot usando aprendizado profundo e Python? 👾","description":"Olá pessoas incríveis desse site, hoje o artigo vai tratar de um assunto que está muito em alta: chatbots!","categories":[],"date":"September 02, 2021","canonical_link":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Como criar um chatbot usando aprendizado profundo e Python? 👾\",\n  \"description\": \"Olá pessoas incríveis desse site, hoje o artigo vai tratar de um assunto que está muito em alta: chatbots!\",\n  \"date\": \"2021-09-02T13:59:38.477Z\",\n  \"categories\": [],\n  \"keywords\": [],\n  \"published\": true\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/b13ea3aed87b4e92f6059a055b02247a/4b190/asset-1.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.85714285714286%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAABAABA//EABYBAQEBAAAAAAAAAAAAAAAAAAMEBf/aAAwDAQACEAMQAAABQdfHORdlMv8A/8QAGRAAAwEBAQAAAAAAAAAAAAAAAAECAxMx/9oACAEBAAEFAtdHL7ULy4VixlM//8QAFxEBAAMAAAAAAAAAAAAAAAAAAhARIf/aAAgBAwEBPwFF3kf/xAAYEQACAwAAAAAAAAAAAAAAAAABAgMQIf/aAAgBAgEBPwFGjC6K/8QAGRAAAwADAAAAAAAAAAAAAAAAAAEQIUFR/9oACAEBAAY/AkkamTs//8QAGhABAAMBAQEAAAAAAAAAAAAAAQARUSEQQf/aAAgBAQABPyGhDv1gPbRkVh2BGMnQ2MfP/9oADAMBAAIAAwAAABAbP//EABgRAAMBAQAAAAAAAAAAAAAAAAABESFx/9oACAEDAQE/EHrbOkP/xAAYEQADAQEAAAAAAAAAAAAAAAAAASERcf/aAAgBAgEBPxDKW4NU/8QAGxABAQACAwEAAAAAAAAAAAAAAREAITFhgdH/2gAIAQEAAT8QG8p6TcyM9csG7fmaZ4DgAW8FRMIKg9PMGABAz//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"asset 1\",\n    \"title\": \"asset 1\",\n    \"src\": \"/static/b13ea3aed87b4e92f6059a055b02247a/29d31/asset-1.jpg\",\n    \"srcSet\": [\"/static/b13ea3aed87b4e92f6059a055b02247a/e52aa/asset-1.jpg 175w\", \"/static/b13ea3aed87b4e92f6059a055b02247a/70ebb/asset-1.jpg 350w\", \"/static/b13ea3aed87b4e92f6059a055b02247a/29d31/asset-1.jpg 700w\", \"/static/b13ea3aed87b4e92f6059a055b02247a/4b190/asset-1.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"Ol\\xE1 pessoas incr\\xEDveis desse site, hoje o artigo vai tratar de um assunto que est\\xE1 muito em alta: chatbots!\"), mdx(\"p\", null, \"Para come\\xE7ar, vamos pensar na forma que interagimos com outros seres humanos e o que seria do mundo se n\\xE3o existisse a comunica\\xE7\\xE3o. Desde o principio, o homem criou formas de se comunicar com o outro e \\xE9 o fundamento para a organiza\\xE7\\xE3o das sociedades. Nos \\xFAltimos tempos o avan\\xE7o da tecnologia vem afetando a forma como essa comunica\\xE7\\xE3o \\xE9 feita, por exemplo, \\xE9 t\\xE3o f\\xE1cil conversarmos com os outros amigos atrav\\xE9s de apps de mensagens, n\\xE3o \\xE9?\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Esse avan\\xE7o n\\xE3o s\\xF3 afeta a forma que nos comunicamos com outras pessoas, como tamb\\xE9m a forma que comunicamos com as m\\xE1quinas. \\xC0 medida que avan\\xE7amos, o modo como comunicamos com os computadores vai se aproximando do natural e \\xE9 a\\xED que entra o campo de pesquisa computacional chamado PLN (NLP, do ingl\\xEAs Natural Language Processing), ou processamento de linguagem natural.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Esse campo de pesquisa estuda como fazer a m\\xE1quina entender a nossa l\\xEDngua escrita, de uma forma que o computador consiga entender a escrita sem conte\\xFAdo definido por programadores e vamos fazer essa implementa\\xE7\\xE3o!\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/4f16aa74fd05fd0e7a401d933bff881a/4b190/asset-2.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.85714285714286%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAABQD/xAAUAQEAAAAAAAAAAAAAAAAAAAAC/9oADAMBAAIQAxAAAAExM1Ioydiv/8QAGhAAAgMBAQAAAAAAAAAAAAAAAQMAAhETIv/aAAgBAQABBQIDYV0ujIoxluKE+lf/xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPwFX/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGhAAAgIDAAAAAAAAAAAAAAAAAQIAERAhMf/aAAgBAQAGPwKc2uQUFF4poT//xAAbEAEAAgIDAAAAAAAAAAAAAAABABEhgUFR0f/aAAgBAQABPyExW5gqCvHkc4jpnCEVW6lVrq6n/9oADAMBAAIAAwAAABBTH//EABcRAAMBAAAAAAAAAAAAAAAAAAABEVH/2gAIAQMBAT8QbkJw/8QAFxEBAQEBAAAAAAAAAAAAAAAAAQARMf/aAAgBAgEBPxAO2Jf/xAAbEAEBAAMBAQEAAAAAAAAAAAABEQAhMWGRof/aAAgBAQABPxBXNGA85iJogrZOehfmb2OBqwF9wUpdbw3BxWvSs7TV/M//2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"asset 2\",\n    \"title\": \"asset 2\",\n    \"src\": \"/static/4f16aa74fd05fd0e7a401d933bff881a/29d31/asset-2.jpg\",\n    \"srcSet\": [\"/static/4f16aa74fd05fd0e7a401d933bff881a/e52aa/asset-2.jpg 175w\", \"/static/4f16aa74fd05fd0e7a401d933bff881a/70ebb/asset-2.jpg 350w\", \"/static/4f16aa74fd05fd0e7a401d933bff881a/29d31/asset-2.jpg 700w\", \"/static/4f16aa74fd05fd0e7a401d933bff881a/4b190/asset-2.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"Atualmente existem v\\xE1rios provedores de NLP, os MLaaS, dispon\\xEDveis para facilitar nossa cria\\xE7\\xE3o de bots. Talvez voc\\xEAs tenham ouvido sobre o IBM Watson ou at\\xE9 mesmo o Dialog Flow do Google, s\\xE3o provedores que j\\xE1 fazem de forma profunda esse processamento e s\\xE3o usados por grandes corpora\\xE7\\xF5es. N\\xF3s do \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Luizalabs\"), \" usamos esses softwares por nos proporcionarem uma comunica\\xE7\\xE3o mais humanizada e flu\\xEDda com o cliente, mas para o pequeno usu\\xE1rio, que talvez queira criar um bot simples ou at\\xE9 mesmo tem curiosidade em como fazer, n\\xE3o seja a melhor escolha, ent\\xE3o hoje vou ensinar para voc\\xEAs como criar um bot simples usando Python e deep learning, o c\\xF3digo completo est\\xE1 no meu \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/thaisribeiro/bot\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"Github\"), \".\"), mdx(\"h3\", {\n    \"id\": \"vamos-instalar\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#vamos-instalar\",\n    \"aria-label\": \"vamos instalar permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Vamos instalar?\"), mdx(\"p\", null, \"Para come\\xE7ar, \\xE9 necess\\xE1rio que voc\\xEA tenha uma vers\\xE3o recente do Python e o pip instalados no seu computador, logo mais, vamos instalar as seguintes bibliotecas:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"pip install nltkpip install numpypip install keraspip install tensorflow\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.nltk.org/\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"NLTK\"), \"\\u200A\\u2014\\u200A\\xC9 uma das ferramentas mais utilizadas para processamento de linguagem natural, foi desenvolvida em Python e tem uma gama muito grande de recursos, como: classifica\\xE7\\xE3o, tokeniza\\xE7\\xE3o, stemming, tagging, parsing e racioc\\xEDnio sem\\xE2ntico. Todas essas fun\\xE7\\xF5es s\\xE3o utilizadas para an\\xE1lise de texto;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://numpy.org/\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"Numpy\"), \"\\u200A\\u2014\\u200A\\xC9 uma biblioteca para a linguagem Python com fun\\xE7\\xF5es para se trabalhar com computa\\xE7\\xE3o num\\xE9rica, e que pode realizar opera\\xE7\\xF5es de \\xE1lgebra linear de maneira muito eficiente;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.tensorflow.org/?hl=pt-br\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"Tensorflow\"), \"\\u200A\\u2014\\u200A\\xC9 uma biblioteca de c\\xF3digo aberto criada para aprendizado de m\\xE1quina, computa\\xE7\\xE3o num\\xE9rica e muitas outras tarefas;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://keras.io/api/\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"Keras\"), \"\\u200A\\u2014\\u200APor \\xFAltimo, e de extrema import\\xE2ncia, usamos o Keras para a estrutura de aprendizado profundo, essa lib poderos\\xEDssima \\xE9 uma das principais APIs de redes neurais de alto n\\xEDvel.\")), mdx(\"p\", null, \"Ser\\xE1 interessante voc\\xEAs lerem como essas bibliotecas funcionam para entender melhor o nosso c\\xF3digo, apesar que vou explicando em todo o decorrer da implementa\\xE7\\xE3o.\"), mdx(\"p\", null, \"Vamos l\\xE1 ent\\xE3o, criaremos nosso dicion\\xE1rio de \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"intents\"), \", quando falamos em inten\\xE7\\xF5es em chatbot, falamos sobre o intuito do usu\\xE1rio ao escrever tal texto. Nosso JSON ir\\xE1 conter a \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"tag\"), \" que define o que \\xE9 aquela inten\\xE7\\xE3o, os \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"patterns\"), \" que ser\\xE3o os exemplos de mensagens enviadas, os \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"responses\"), \" que s\\xE3o os feedbacks enviados pelo bot e o \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"context\"), \", se quisermos usar manipula\\xE7\\xE3o de contexto de mensagens:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"{  \\\"intents\\\": [    {      \\\"tag\\\": \\\"welcome\\\",      \\\"patterns\\\": [\\\"Oi\\\", \\\"bom dia\\\", \\\"boa tarde\\\", \\\"boa noite\\\", \\\"good morning\\\", \\\"Hi\\\", \\\"hello\\\", \\\"Ol\\xE1\\\"],      \\\"responses\\\": [\\\"Ol\\xE1, eu sou sua assistente virtual, em que posso te ajudar?\\\"],      \\\"context\\\": [\\\"\\\"]    },    {      \\\"tag\\\": \\\"who_are_you\\\",      \\\"patterns\\\": [\\\"qual seu nome?\\\", \\\"quem \\xE9 voc\\xEA?\\\", \\\"como voc\\xEA chama?\\\", \\\"nome?\\\"],      \\\"responses\\\": [\\\"Eu sou uma assistente virtual, ainda n\\xE3o tenho nome.\\\"],      \\\"context\\\": [\\\"\\\"]    },    {      \\\"tag\\\": \\\"love\\\",      \\\"patterns\\\": [\\\"te amo\\\", \\\"linda\\\", \\\"querida\\\", \\\"casa comigo?\\\", \\\"maravilhosa\\\"],      \\\"responses\\\": [\\\"Awwwn, muito obrigada <3\\\"],      \\\"context\\\": [\\\"\\\"]    },    {      \\\"tag\\\": \\\"censored\\\",      \\\"patterns\\\": [\\\"feia\\\", \\\"boba\\\", \\\"chata\\\", \\\"vai pro inferno\\\", \\\"puta\\\", \\\"quer casar comigo?\\\", \\\"sua gostosa\\\"],      \\\"responses\\\": [\\\"N\\xE3o toleramos nenhum tipo de ass\\xE9dio.\\\"],      \\\"context\\\": [\\\"\\\"]    },    {      \\\"tag\\\": \\\"thanks\\\",      \\\"patterns\\\": [\\\"obrigada\\\", \\\"tks\\\", \\\"thank you\\\", \\\"valeu\\\", \\\"obrigada pela ajuda\\\", \\\"muito obrigada\\\"],      \\\"responses\\\": [\\\"De nada ;)\\\", \\\"Agrade\\xE7o seu contato, volte sempre!\\\"],      \\\"context\\\": [\\\"\\\"]    },    {      \\\"tag\\\": \\\"anything_else\\\",      \\\"patterns\\\": [],      \\\"responses\\\": [\\\"Desculpa, n\\xE3o entendi o que voc\\xEA falou, tente novamente!\\\"],      \\\"context\\\": [\\\"\\\"]    }  ]}\\n\")), mdx(\"h3\", {\n    \"id\": \"treinando-e-criando-nossomodelo\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#treinando-e-criando-nossomodelo\",\n    \"aria-label\": \"treinando e criando nossomodelo permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Treinando e criando nosso\\xA0modelo\"), mdx(\"p\", null, \"Agora, vamos criar o arquivo \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"train.py\"), \", onde vamos ter o c\\xF3digo para ler os dados de linguagem natural e usar a rede neural sequencial keras para criar nosso \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"modelo\"), \".\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Nesse c\\xF3digo vamos dividir a explica\\xE7\\xE3o em algumas partes, para facilitar o entendimento.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Realizamos a importa\\xE7\\xE3o e configura\\xE7\\xE3o inicial das libs que iremos utilizar:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"import jsonimport pickleimport nltkimport randomimport numpy as npfrom nltk.stem import WordNetLemmatizerfrom keras.models import Sequentialfrom keras.layers import Dense, Activation, Dropoutfrom keras.optimizers import SGDnltk.download('punkt')nltk.download('wordnet')lemmatizer = WordNetLemmatizer()\\n\")), mdx(\"p\", null, \"Inicializamos a nossa lista de palavras, classes, documentos e definimos quais palavras ser\\xE3o ignoradas, percorremos a nossa lista de inten\\xE7\\xF5es, que foram lidas pelo c\\xF3digo e com ajuda do nltk fazemos a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://nltk.sourceforge.net/doc/pt-br/tokenize.html\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"tokeniza\\xE7\\xE3o\"), \" dos patterns e adicionamos na lista de palavras, adicionamos tamb\\xE9m aos documentos para termos a identifica\\xE7\\xE3o da tag para cada palavra e adicionamos as tags a nossa lista de classe:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"# inicializaremos nossa lista de palavras, classes, documentos e # definimos quais palavras ser\\xE3o ignoradaswords = []documents = []intents = json.loads(open('intents.json').read())# adicionamos as tags em nossa lista de classesclasses = [i['tag'] for i in intents['intents']]ignore_words = [\\\"!\\\", \\\"@\\\", \\\"#\\\", \\\"$\\\", \\\"%\\\", \\\"*\\\", \\\"?\\\"]# \\xE9 feita a leitura do arquivo intents.json e transformado em jsonintents = json.loads(open('intents.json').read())# percorremos nosso array de objetosfor intent in intents['intents']:    for pattern in intent['patterns']:        # com ajuda no nltk fazemos aqui a tokeniza\\xE7ao dos patterns         # e adicionamos na lista de palavras        word = nltk.word_tokenize(pattern)        words.extend(word)        # adiciona aos documentos para identificarmos a tag para a mesma        documents.append((word, intent['tag']))\\n\")), mdx(\"p\", null, \"Em seguida, vamos lematizar, ou seja, transformar as palavras em seus significados b\\xE1sicos, com o objetivo de restringir tudo ao n\\xEDvel mais simples poss\\xEDvel.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Um exemplo de lematiza\\xE7\\xE3o ocorre com verbos, tipo, escrevendo, escreveu e escreve tem o mesmo lema que \\xE9 escrever.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Logo, classificamos nossas listas e estamos prontos para construir o modelo de aprendizado profundo.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"# lematizamos as palavras ignorando os palavras da lista ignore_wordswords = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]# classificamos nossas listaswords = sorted(list(set(words)))classes = sorted(list(set(classes)))# salvamos as palavras e classes nos arquivos pklpickle.dump(words, open('words.pkl', 'wb'))pickle.dump(classes, open('classes.pkl', 'wb'))\\n\")), mdx(\"p\", null, \"Vamos come\\xE7ar nosso treinamento criando um array vazio de treinamento e criando uma lista de sa\\xEDdas vazias de acordo com o tamanho das nossas classes.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Percorremos nossos documentos, inicializamos um array de \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bag\"), \" vazio, inserimos no nosso \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"pattern\", \"_\", \"word\"), \" a nossa palavra correspondente \\xE0quele padr\\xE3o, lematizamos cada uma delas na tentativa de representar palavras relacionadas, inserimos 1 no bag se a correspond\\xEAncia de palavras for encontrada no pattern atual e utilizamos o \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"output\", \"_\", \"row\"), \" como uma chave para a lista, onde a sa\\xEDda ser\\xE1 0 para cada tag e 1 para a tag atual.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Ap\\xF3s isso embaralhamos nosso conjunto de treinamentos, transformamos em numpy array e definimos uma lista de treinos, sendo x os patterns e y as inten\\xE7\\xF5es:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"# inicializamos o treinamentotraining = []output_empty = [0] * len(classes)for document in documents:    # inicializamos o saco de palavras     bag = []    # listamos as palavras do pattern    pattern_words = document[0]    # lematizamos cada palavra     # na tentativa de representar palavras relacionadas    pattern_words = [lemmatizer.lemmatize( word.lower()) for word in pattern_words]    # criamos nosso conjunto de palavras com 1,     # se a correspond\\xEAncia de palavras for encontrada no padr\\xE3o     atual    for word in words:        bag.append(1) if word in pattern_words else bag.append(0)    # output_row atuar\\xE1 como uma chave para a lista,     # onde a saida ser\\xE1 0 para cada tag e 1 para a tag atual    output_row = list(output_empty)    output_row[classes.index(document[1])] = 1    training.append([bag, output_row])# embaralhamos nosso conjunto de treinamentos e transformamos em numpy arrayrandom.shuffle(training)training = np.array(training)# criamos lista de treino sendo x os patterns e y as inten\\xE7\\xF5esx = list(training[:, 0])y = list(training[:, 1])\\n\")), mdx(\"p\", null, \"Com nossos dados de treinamento prontos, usaremos o modelo de aprendizado profundo keras chamado \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"sequencial\"), \", esse modelo sequencial \\xE9 uma das redes neurais mais simples, um perceptron multicamadas, que em particular tem 3 camadas, com a primeira tendo 128 neur\\xF4nios, a segunda 64 e a terceira tendo o n\\xFAmero de inten\\xE7\\xF5es igual o n\\xFAmero de neur\\xF4nios, o objetivo dessa rede \\xE9 tentar prever qual base escolher de acordo com alguns dados.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Esse modelo ser\\xE1 treinado com \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://matheusfacure.github.io/2017/02/20/MQO-Gradiente-Descendente/\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"descida gradiente estoc\\xE1stica\"), \" que \\xE9 um t\\xF3pico beeeem complexo, mas que tem muito conte\\xFAdo no senhor google e no link disponibilizado.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Depois que nosso modelo \\xE9 treinado ser\\xE1 salvo no \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"model.h5\"), \" como numpy array e \\xE9 com esse modelo que vamos criar nossa GUI do chatbot.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"# Criamos nosso modelo com 3 camadas. # Primeira camada de 128 neur\\xF4nios, # segunda camada de 64 neur\\xF4nios e terceira camada de sa\\xEDda # cont\\xE9m n\\xFAmero de neur\\xF4nios igual ao n\\xFAmero de inten\\xE7\\xF5es para prever a inten\\xE7\\xE3o de sa\\xEDda com softmax\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"model = Sequential()model.add(Dense(128, input_shape=(len(x[0]),), activation='relu'))model.add(Dropout(0.5))model.add(Dense(64, activation='relu'))model.add(Dropout(0.5))model.add(Dense(len(y[0]), activation='softmax'))# O modelo \\xE9 compilado com descida de gradiente estoc\\xE1stica # com gradiente acelerado de Nesterov.# A ideia da otimiza\\xE7\\xE3o do Momentum de Nesterov, ou Nesterov Accelerated Gradient (NAG), # \\xE9 medir o gradiente da fun\\xE7\\xE3o de custo n\\xE3o na posi\\xE7\\xE3o local,# mas ligeiramente \\xE0 frente na dire\\xE7\\xE3o do momentum. # A \\xFAnica diferen\\xE7a entre a otimiza\\xE7\\xE3o de Momentum \\xE9 que o gradiente \\xE9 medido em \\u03B8 + \\u03B2m em vez de em \\u03B8.\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)model.compile(loss='categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])# ajustamos e salvamos o modelom = model.fit(np.array(x), np.array(y), epochs=200, batch_size=5, verbose=1)model.save('model.h5', m)print(\\\"fim\\\")\\n\")), mdx(\"h3\", {\n    \"id\": \"extraindo-os-dados-e-criando-nossa-interface-gui\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#extraindo-os-dados-e-criando-nossa-interface-gui\",\n    \"aria-label\": \"extraindo os dados e criando nossa interface gui permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Extraindo os dados e criando nossa interface (GUI)\"), mdx(\"p\", null, \"Vamos criar um arquivo \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"extract.py\"), \" para extrair os dados e lidar com as previs\\xF5es e probabilidades das mensagens em conjunto com o modelo treinado e um arquivo chamado \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bot.py\"), \" que ser\\xE1 a nossa interface gr\\xE1fica.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Nosso arquivo extract tem 4 fun\\xE7\\xF5es, sendo essas:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"clear\", \"_\", \"writing\"), \" que \\xE9 a respons\\xE1vel por limpar as palavras inseridas, ou seja, fazer a higieniza\\xE7\\xE3o da mensagem enviada pelo usu\\xE1rio\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"bag\", \"_\", \"of\", \"_\", \"words\"), \" \\xE9 a fun\\xE7\\xE3o respons\\xE1vel por criar um pacote de palavras que ser\\xE1 usado para as previs\\xF5es.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"class\", \"_\", \"prediction\"), \" faz a previs\\xE3o do pacote de palavras, usamos como limite de erro 0.25 para evitarmos overfitting e classificamos esses resultados por for\\xE7a da probabilidade;\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"get\", \"_\", \"response\"), \" \\xE9 a fun\\xE7\\xE3o que vamos usar depois que fizermos todo o processo acima, com nosso retorno de inten\\xE7\\xE3o, verificamos qual as mensagens de retorno do json, usamos o random para pegarmos apenas uma resposta da lista.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"import randomimport numpy as npimport pickleimport nltkfrom nltk.stem import WordNetLemmatizerlemmatizer = WordNetLemmatizer()words = pickle.load(open('words.pkl', 'rb'))classes = pickle.load(open('classes.pkl', 'rb'))def clear_writing(writing):    \\\"\\\"\\\"        Limpa todas as senten\\xE7as inseridas.    \\\"\\\"\\\"    #tokeniza todas as frases inseridas, lematiza cada uma delas e retorna    sentence_words = nltk.word_tokenize(writing)    return [lemmatizer.lemmatize(word.lower()) for word in sentence_words]# retorna 0 ou 1 para cada palavra da bolsa de palavrasdef bag_of_words(writing, words):    \\\"\\\"\\\"        Pega as senten\\xE7as que s\\xE3o limpas e cria um pacote de palavras que s\\xE3o usadas         para classes de previs\\xE3o que s\\xE3o baseadas nos resultados que obtivemos treinando o modelo.    \\\"\\\"\\\"    # tokenize the pattern    sentence_words = clear_writing(writing)    # cria uma matriz de N palavras    bag = [0]*len(words)    for setence in sentence_words:        for i, word in enumerate(words):            if word == setence:                # atribui 1 no pacote de palavra se a palavra atual estiver na posi\\xE7\\xE3o da frase                bag[i] = 1    return(np.array(bag))def class_prediction(writing, model):    \\\"\\\"\\\"      Faz a previsao do pacote de palavras, usamos como limite de erro 0.25 para evitarmos overfitting      e classificamos esses resultados por for\\xE7a da probabilidade.    \\\"\\\"\\\"    # filtra as previs\\xF5es abaixo de um limite 0.25    prevision = bag_of_words(writing, words)    response_prediction = model.predict(np.array([prevision]))[0]    results = [[index, response] for index, response in enumerate(response_prediction) if response > 0.25]        # verifica nas previs\\xF5es se n\\xE3o h\\xE1 1 na lista, se n\\xE3o h\\xE1 envia a resposta padr\\xE3o (anything_else)     # ou se n\\xE3o corresponde a margem de erro    if \\\"1\\\" not in str(prevision) or len(results) == 0 :        results = [[0, response_prediction[0]]]    # classifica por for\\xE7a de probabilidade    results.sort(key=lambda x: x[1], reverse=True)    return [{\\\"intent\\\": classes[r[0]], \\\"probability\\\": str(r[1])} for r in results]def get_response(intents, intents_json):    \\\"\\\"\\\"        pega a lista gerada e verifica o arquivo json e produz a maior parte das respostas com a maior probabilidade.    \\\"\\\"\\\"    tag = intents[0]['intent']    list_of_intents = intents_json['intents']    for idx in list_of_intents:        if idx['tag'] == tag:            # caso as respostas sejam um array contendo mais de uma,             # usamos a fun\\xE7\\xE3o de random para pegar uma resposta randomica da nossa lista            result = random.choice(idx['responses'])            break    return result\\n\")), mdx(\"p\", null, \"Por fim, vamos criar nossa interface gr\\xE1fica utilizando o m\\xF3dulo \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.python.org/3/library/tkinter.html\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"tkinter\"), \" do Python, que \\xE9 um toolkit padr\\xE3o para cria\\xE7\\xE3o de GUI. Para n\\xE3o extender muito e visto que esse m\\xF3dulo tem uma documenta\\xE7\\xE3o muito boa, vou deixar o c\\xF3digo com os coment\\xE1rios do que fiz para criar a interface:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"import jsonimport tkinterfrom tkinter import *from extract import class_prediction, get_responsefrom keras.models import load_model# extraimos o modelo usando o kerasmodel = load_model('model.h5')# carregamos nossas inten\\xE7\\xF5esintents = json.loads(open('intents.json').read())base = Tk()base.title(\\\"Chatbot\\\")base.geometry(\\\"400x500\\\") base.resizable(width=FALSE, height=FALSE)def chatbot_response(msg):    \\\"\\\"\\\"        Resposta do bot    \\\"\\\"\\\"    ints = class_prediction(msg, model)    res = get_response(ints, intents)    return resdef send():    \\\"\\\"\\\"        Envia a mensagem    \\\"\\\"\\\"    msg = EntryBox.get(\\\"1.0\\\", 'end-1c').strip()    EntryBox.delete(\\\"0.0\\\", END)    if msg != '':        Chat.config(state=NORMAL)        Chat.insert(END, f\\\"Voc\\xEA: {msg}\\\\n\\\\n\\\")        Chat.config(foreground=\\\"#000000\\\", font=(\\\"Arial\\\", 12))        response = chatbot_response(msg)        Chat.insert(END, f\\\"Bot: {response}\\\\n\\\\n\\\")        Chat.config(state=DISABLED)        Chat.yview(END)# Cria a janela do chatChat = Text(base, bd=0, bg=\\\"white\\\", height=\\\"8\\\", width=\\\"50\\\", font=\\\"Arial\\\",)Chat.config(state=DISABLED)# Vincula a barra de rolagem \\xE0 janela de bate-paposcrollbar = Scrollbar(base, command=Chat.yview)Chat['yscrollcommand'] = scrollbar.set# Cria o bot\\xE3o de envio de mensagem, onde o comando envia para a fun\\xE7\\xE3o de sendSendButton = Button(base, font=(\\\"Verdana\\\", 10, 'bold'), text=\\\"Enviar\\\", width=\\\"12\\\", height=2, bd=0, bg=\\\"#666\\\", activebackground=\\\"#333\\\", fg='#ffffff', command=send)# Cria o box de textoEntryBox = Text(base, bd=0, bg=\\\"white\\\", width=\\\"29\\\", height=\\\"2\\\", font=\\\"Arial\\\")# Coloca todos os componentes na telascrollbar.place(x=376, y=6, height=386)Chat.place(x=6, y=6, height=386, width=370)EntryBox.place(x=128, y=401, height=50, width=260)SendButton.place(x=6, y=401, height=50)base.mainloop()\\n\")), mdx(\"h3\", {\n    \"id\": \"executando-nossocódigo\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#executando-nossoc%C3%B3digo\",\n    \"aria-label\": \"executando nossocódigo permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Executando nosso\\xA0c\\xF3digo\"), mdx(\"p\", null, \"Antes de executar nosso c\\xF3digo, vamos criar 3 arquivos na raiz do projeto \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"model.h5\"), \", \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"words.pkl\"), \" e \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"classes.pkl\"), \". Se voc\\xEA usa Windows, ter\\xE1 que instalar um servidor chamado Xming.\"), mdx(\"p\", null, \"Vamos come\\xE7ar treinando nosso modelo e depois de treinado executamos nosso \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bot.py\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"python train.py\\n\")), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/7eba5606d7372456079ffe8ed712bad9/4b190/asset-3.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"55.42857142857143%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAIDAQX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAAB583nZoof/8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQABBQJf/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAEQEUEx/9oACAEBAAE/IW8LRY+mx//aAAwDAQACAAMAAAAQTP8A/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHBAAAgICAwAAAAAAAAAAAAAAAAERIRAxUXGR/9oACAEBAAE/EFO00OSpIcP02D27x//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"asset 3\",\n    \"title\": \"asset 3\",\n    \"src\": \"/static/7eba5606d7372456079ffe8ed712bad9/29d31/asset-3.jpg\",\n    \"srcSet\": [\"/static/7eba5606d7372456079ffe8ed712bad9/e52aa/asset-3.jpg 175w\", \"/static/7eba5606d7372456079ffe8ed712bad9/70ebb/asset-3.jpg 350w\", \"/static/7eba5606d7372456079ffe8ed712bad9/29d31/asset-3.jpg 700w\", \"/static/7eba5606d7372456079ffe8ed712bad9/4b190/asset-3.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"python bot.py\\n\")), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"405px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/f2176428b3e1104eef86c7edbe518365/02e66/asset-4.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"134.2857142857143%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAbABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAgADBAX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAAB9lNHLOg78mlKEf/EABsQAAICAwEAAAAAAAAAAAAAAAECADEDECES/9oACAEBAAEFAgOeYw6Kj2uVNNYA3//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8BH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8BH//EABkQAAMAAwAAAAAAAAAAAAAAAAEQMQASIf/aAAgBAQAGPwKZEGBt1x//xAAfEAACAQMFAQAAAAAAAAAAAAAAEQEQMWEhQVFxofD/2gAIAQEAAT8hdBysfDIdh5qstHAh4k12EdSj6Hmn/9oADAMBAAIAAwAAABAD/Az/xAAXEQADAQAAAAAAAAAAAAAAAAAAARAR/9oACAEDAQE/EDXf/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAEQEf/aAAgBAgEBPxAxX//EAB8QAQACAgEFAQAAAAAAAAAAAAEAESFRMRBxkaGx4f/aAAgBAQABPxC8IUNqEAXTzIMkY3PWfOnB2hJiqAHLqV/CWFFxqCEYBsF3LbeYq8rP/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"asset 4\",\n    \"title\": \"asset 4\",\n    \"src\": \"/static/f2176428b3e1104eef86c7edbe518365/02e66/asset-4.jpg\",\n    \"srcSet\": [\"/static/f2176428b3e1104eef86c7edbe518365/e52aa/asset-4.jpg 175w\", \"/static/f2176428b3e1104eef86c7edbe518365/70ebb/asset-4.jpg 350w\", \"/static/f2176428b3e1104eef86c7edbe518365/02e66/asset-4.jpg 405w\"],\n    \"sizes\": \"(max-width: 405px) 100vw, 405px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"Bom, conclu\\xEDmos aqui nosso primeiro chatbot e estou feliz de poder compartilhar com voc\\xEAs. Esse projeto por mais simples que seja nos d\\xE1 habilidades \\xFAteis para a ci\\xEAncia de dados, claro que tem muito ch\\xE3o para entendermos aprendizado profundo, mas estamos no caminho.\"), mdx(\"p\", null, \"Gostou? Ent\\xE3o reage ao post e compartilhe com seus amigos para que eu continue trazendo conte\\xFAdo interessantes para voc\\xEAs!\"));\n}\n;\nMDXContent.isMDXComponent = true;"}},"pageContext":{"id":"a6478b4e-3a5b-574f-8b3f-772447cd612d","previous":{"id":"890f0a75-f726-5db0-932d-45f2d6a4852f","fields":{"slug":"/um-jeito-facil-de-fazer-e-jogar-snake-usando-python/","published":true},"frontmatter":{"redirect_from":null,"title":"Criando o jogo da cobrinha com python. 🐍"}},"next":{"id":"faae9b86-e885-5d73-bae6-3d389d944ebd","fields":{"slug":"/vamos-converter-um-texto-em-escrita-a-mao-usando-python/","published":true},"frontmatter":{"redirect_from":null,"title":"Vamos converter um texto em escrita à mão usando Python?"}}}},"staticQueryHashes":["2589769190","3617321856","4131332129","759284515"]}