{"componentChunkName":"component---src-templates-blog-post-js","path":"/chica-assistente-virtual-mineira-graciosa/","result":{"data":{"site":{"siteMetadata":{"siteUrl":"https://thais-ribeiro-blog.netlify.com","githubUrl":"https://github.com/thaisribeiro/blog-thais"}},"mdx":{"fields":{"slug":"/chica-assistente-virtual-mineira-graciosa/"},"timeToRead":3,"frontmatter":{"title":"CHICA - A assistente virtual mineira e graciosa ü§ñ","description":"Oi meus trem b√£o, tudo bem com voc√™s? Pois eu t√¥, bem e animada para trazer um conte√∫do fresquinho juntando o que j√° ensinei por aqui e no twitter...","categories":[],"date":"December 11, 2021","canonical_link":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"CHICA - A assistente virtual mineira e graciosa ü§ñ\",\n  \"description\": \"Oi meus trem b√£o, tudo bem com voc√™s? Pois eu t√¥, bem e animada para trazer um conte√∫do fresquinho juntando o que j√° ensinei por aqui e no twitter...\",\n  \"date\": \"2021-12-11T01:24:32.124Z\",\n  \"categories\": [],\n  \"published\": true\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fgbq99aupa8x05mfwzmu.png\",\n    \"alt\": null\n  })), mdx(\"p\", null, \"Oi meus trem b\\xE3o, tudo bem com voc\\xEAs? Pois eu t\\xF4, bem e animada para trazer um conte\\xFAdo fresquinho juntando o que j\\xE1 ensinei por aqui e no twitter, mas para voc\\xEAs n\\xE3o ficarem no escuro eu vou dar um breve resumo sobre essas \\u201Ccoisas\\u201D.\\nA cada ano que passa est\\xE1 cada vez mais f\\xE1cil ser pregui\\xE7oso e pedir para um assistente virtual realizar tarefas simples para voc\\xEA:\\n\\u2014 Alexa, toca aquela l\\xE1 da Mar\\xEDlia\\n\\u2014 Alexa, que dia \\xE9 hoje?\\n\\u2014 Siri, ligue para mam\\xE3e.\\nMas voc\\xEAs j\\xE1 se perguntaram como esses assistentes virtuais funcionam? N\\xE3o? Vou te contar um pouco como funciona e te ensinar a fazer uma assistente personalizada baseada na \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/thaisribeiro/chica\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"CHICA\"), \", minha assistente mineirinha e graciosa.\"), mdx(\"p\", null, mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mywm5g5ow1bfhe8rnr1z.png\",\n    \"alt\": null\n  })), mdx(\"p\", null, \"Longe de ser uma siri ou uma Alexa, mas usando os mesmos conceitos, criei a Chica para ajudar as pessoas entenderem como funciona esse tipo de IA.\\nO foco principal hoje \\xE9 falarmos sobre reconhecimento de voz de forma resumida, porque uma discuss\\xE3o completa caberia em um livro, ou v\\xE1rios.\\nO reconhecimento de voz tem suas ra\\xEDzes em pesquisas feitas nos anos 50 e os primeiros sistemas eram limitados a um vocabul\\xE1rio de uma d\\xFAzia de palavras, at\\xE9 chegarmos ao ponto que estamos hoje, esses sistemas percorreram um grande caminho desde ent\\xE3o, e como eles trabalham por debaixo do cap\\xF4?\"), mdx(\"p\", null, \"O primeiro componente do reconhecimento de fala, \\xE9 a fala \\uD83D\\uDDE3\\uFE0F, ela \\xE9 convertida de som f\\xEDsico em sinal el\\xE9trico com um microfone, e em seguida, em dados digitais com um conversor anal\\xF3gico-digital. Uma vez digitalizado, pode-se usar v\\xE1rios modelos para transcrever o \\xE1udio em texto.\\nA maioria dos sistemas atuais usam um modelo conhecido como \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Hidden_Markov_model\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"Modelo Oculto de Markov\"), \"(HMM), que funciona supondo que um sinal de voz, quando visto em uma escala de tempo curta o suficiente (dez milisegundos), pode ser razoavelmente aproximado como um processo estacion\\xE1rio, no qual as estat\\xEDsticas n\\xE3o mudam ao longo do tempo.\"), mdx(\"p\", null, \"Em um modelo HMM, o sinal de voz \\xE9 dividido em fragmentos de 10 milisegundos, o espectro de pot\\xEAncia* de cada fragmento \\xE9 mapeado para um vetor de n\\xFAmeros reais conhecido como coeficientes cepstrais. A dimens\\xE3o desse vetor \\xE9 pequena e a sa\\xEDda final do HMM \\xE9 uma sequ\\xEAncia desses vetores. Para decodificar o que foi falado em texto, grupos desses vetores s\\xE3o combinados com um ou mais fonemas e um algoritmo especial \\xE9 aplicado para determinar a palavra/frase mais prov\\xE1vel produzida. Esses fonemas exige treinamento, j\\xE1 que um som varia de pessoa para pessoa.\"), mdx(\"p\", null, \"Sugiro que voc\\xEAs pesquisem mais a fundo sobre esse modelo para entender como os c\\xE1lculos e os treinamentos s\\xE3o feitos. A boa not\\xEDcia para o \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"pythonista\"), \" \\xE9 que para tudo na vida hoje em dia tem biblioteca.Hoje existem v\\xE1rios servi\\xE7os de reconhecimento de voz dispon\\xEDveis por meio de API, e n\\xF3s usaremos o \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SpeechRecognition\"), \".\"), mdx(\"h2\", {\n    \"id\": \"speechrecognition\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#speechrecognition\",\n    \"aria-label\": \"speechrecognition permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"SpeechRecognition\"), mdx(\"p\", null, \"SpeechRecognition \\xE9 um recurso importante usado na automa\\xE7\\xE3o residencial e em dispositivos de intelig\\xEAncia artificial.\\nA principal fun\\xE7\\xE3o desta biblioteca \\xE9 fazer o que explicamos ali em cima: tentar entender tudo o que os humanos falam e converter a fala em texto.\\nA flexibilidade e facilidade de uso do pacote, o tornam uma escolha excelente para qualquer projeto Python. \"), mdx(\"h3\", {\n    \"id\": \"instalando\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#instalando\",\n    \"aria-label\": \"instalando permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Instalando\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"pip install SpeechRecognition\\n\")), mdx(\"p\", null, \"No nosso caso vamos precisar instalar tamb\\xE9m o PyAudio para capturarmos a entrada do microfone.\"), mdx(\"h2\", {\n    \"id\": \"criando-a-chica\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#criando-a-chica\",\n    \"aria-label\": \"criando a chica permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Criando a Chica\"), mdx(\"p\", null, \"Na assistente acoplei um nlp para identificar a inten\\xE7\\xE3o do usu\\xE1rio, eu expliquei \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://dev.to/thaisribeiro/como-criar-um-bot-usando-deep-learning-e-python-2d55\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"como fazer um bot usando aprendizado profundo\"), \" aqui no dev.to e l\\xE1 no medium, \\xE9 importante voc\\xEAs lerem para entender como nosso modelo \\xE9 treinado e como s\\xE3o classificadas as inten\\xE7\\xF5es.\\nSupondo que temos nosso modelo treinado e nossas inten\\xE7\\xF5es definidas, vamos criar nosso arquivo principal que ser\\xE1 o cara respons\\xE1vel por capturar a voz do seu microfone e identificar o que voc\\xEA quis dizer, a explica\\xE7\\xE3o est\\xE1 comentada no c\\xF3digo.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"import os\\nimport pathlib\\nimport random\\nimport pytz\\nimport speech_recognition as sr\\nimport wikipedia\\nimport pyjokes\\nfrom datetime import datetime, timezone\\nfrom speech import to_speak\\nfrom nlp.extract import get_response, class_prediction\\nfrom pydub import AudioSegment\\nfrom pydub.playback import play\\nfrom youtube import run_youtube\\n\\nwikipedia.set_lang(\\\"pt\\\")\\npath = pathlib.Path(__file__).parent.resolve()\\nIST = pytz.timezone('America/Sao_Paulo')\\n\\nlistener = sr.Recognizer()\\n\\n\\ndef listening():\\n    # captura o som do microfone\\n    with sr.Microphone() as src:\\n        print('listening...')\\n        listener.adjust_for_ambient_noise(src)\\n        voice = listener.listen(src)\\n        try:\\n            event = listener.recognize_google(voice, language='pt-BR')\\n            event = event.lower()\\n        except:\\n            event = 'anything_else'\\n\\n    return event\\n\\n\\ndef voice_chica(tag):\\n    song = AudioSegment.from_mp3(f'{path}/audios/{tag}.mp3')\\n    play(song)\\n\\ndef run():\\n    \\\"\\\"\\\"\\n        M\\xE9todo que ir\\xE1 iniciar nossa assistente virtual e o reconhecimento de voz\\n        nesse momento a voz da chica ser\\xE1 o default.\\n        Quem enjoar da minha voz, pode usar o\\n        to_speak passando o random.choices(response) no lugar de voice_chica\\n\\n    \\\"\\\"\\\"\\n    event = listening()\\n    # retorna a voz transcrita, que foi falada ao microfone\\n    print(f'evento: {event}')\\n    \\n    # \\xE9 enviado para a classe de predi\\xE7\\xE3o, para identificar as inten\\xE7\\xF5es e assim buscar a resposta mais coerente se existir, caso n\\xE3o exista cai no fallback.\\nEsse processo de NLP foi explicado no outro artigo.\\n    intents = class_prediction(event)\\n    response, context, tag = get_response(intents)\\n\\n    if tag == 'song':\\n        voice_chica(tag)\\n        run_youtube(event)\\n    elif tag == 'hours':\\n        voice_chica(tag)\\n        hours_speak = f'{datetime.now(IST).hour} horas e {datetime.now(IST).minute} minutos'\\n        to_speak(hours_speak)\\n        voice_chica(f'{tag}2')\\n    elif tag == 'days':\\n        voice_chica(tag)\\n        days_speak = f'{datetime.now(IST).day}'\\n        to_speak(days_speak)\\n    elif tag == 'search':\\n        voice_chica(tag)\\n        voice_chica(f'{tag}2')\\n        info = wikipedia.summary(event, 1)\\n        to_speak(info)\\n    else:\\n        # voice_chica \\xE9 um m\\xE9todo que ir\\xE1 reproduzir os \\xE1udios com a minha voz haha e to_speak com a voz do google.\\n        voice_chica(tag)\\n\\nwhile True:\\n    run()\\n\\n\")), mdx(\"p\", null, \"Esse foi um exemplo de como ficou a classe principal, o projeto \\xE9 open source e est\\xE1 no meu \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/thaisribeiro/chica\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"reposit\\xF3rio\"), \".\\nBom, vou deixar voc\\xEAs colocarem a m\\xE3o na massa e executarem o c\\xF3digo, assim como tentar entend\\xEA-lo tamb\\xE9m haha, vou ficando por aqui, espero que tenham gostado e pe\\xE7o gentilmente que leve esse e os outros artigos aos seus amigos, assim voc\\xEA estar\\xE1 compartilhando informa\\xE7\\xE3o e incentivando o meu trabalho.\\nAt\\xE9 mais.\"));\n}\n;\nMDXContent.isMDXComponent = true;"}},"pageContext":{"id":"1b5565df-09e8-5cc2-97c8-d4a0e5a05f95","previous":{"id":"faae9b86-e885-5d73-bae6-3d389d944ebd","fields":{"slug":"/vamos-converter-um-texto-em-escrita-a-mao-usando-python/","published":true},"frontmatter":{"redirect_from":null,"title":"Vamos converter um texto em escrita √† m√£o usando Python?"}},"next":{"id":"23919088-cc87-5939-b1e5-d71ee24b01f9","fields":{"slug":"/converter-pdf-em-audiobook/","published":true},"frontmatter":{"redirect_from":null,"title":"Converter PDF em Audiobook de forma simples com Python üìî"}}}},"staticQueryHashes":["2589769190","3617321856","4131332129","759284515"]}