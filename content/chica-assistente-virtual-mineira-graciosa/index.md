---
title: "CHICA - A assistente virtual mineira e graciosa \U0001F916"
description: "Oi meus trem b√£o, tudo bem com voc√™s? Pois eu t√¥, bem e animada para trazer um conte√∫do fresquinho juntando o que j√° ensinei por aqui e no twitter..."
date: "2021-12-11T01:24:32.124Z"
categories: []
published: true
---

![](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fgbq99aupa8x05mfwzmu.png)

Oi meus trem b√£o, tudo bem com voc√™s? Pois eu t√¥, bem e animada para trazer um conte√∫do fresquinho juntando o que j√° ensinei por aqui e no twitter, mas para voc√™s n√£o ficarem no escuro eu vou dar um breve resumo sobre essas "coisas".
A cada ano que passa est√° cada vez mais f√°cil ser pregui√ßoso e pedir para um assistente virtual realizar tarefas simples para voc√™:
‚Äî Alexa, toca aquela l√° da Mar√≠lia
‚Äî Alexa, que dia √© hoje?
‚Äî Siri, ligue para mam√£e.
Mas voc√™s j√° se perguntaram como esses assistentes virtuais funcionam? N√£o? Vou te contar um pouco como funciona e te ensinar a fazer uma assistente personalizada baseada na [CHICA](https://github.com/thaisribeiro/chica), minha assistente mineirinha e graciosa.

![](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mywm5g5ow1bfhe8rnr1z.png)

Longe de ser uma siri ou uma Alexa, mas usando os mesmos conceitos, criei a Chica para ajudar as pessoas entenderem como funciona esse tipo de IA.
O foco principal hoje √© falarmos sobre reconhecimento de voz de forma resumida, porque uma discuss√£o completa caberia em um livro, ou v√°rios. 
O reconhecimento de voz tem suas ra√≠zes em pesquisas feitas nos anos 50 e os primeiros sistemas eram limitados a um vocabul√°rio de uma d√∫zia de palavras, at√© chegarmos ao ponto que estamos hoje, esses sistemas percorreram um grande caminho desde ent√£o, e como eles trabalham por debaixo do cap√¥?

O primeiro componente do reconhecimento de fala, √© a fala üó£Ô∏è, ela √© convertida de som f√≠sico em sinal el√©trico com um microfone, e em seguida, em dados digitais com um conversor anal√≥gico-digital. Uma vez digitalizado, pode-se usar v√°rios modelos para transcrever o √°udio em texto.
A maioria dos sistemas atuais usam um modelo conhecido como [Modelo Oculto de Markov](https://en.wikipedia.org/wiki/Hidden_Markov_model)(HMM), que funciona supondo que um sinal de voz, quando visto em uma escala de tempo curta o suficiente (dez milisegundos), pode ser razoavelmente aproximado como um processo estacion√°rio, no qual as estat√≠sticas n√£o mudam ao longo do tempo.

Em um modelo HMM, o sinal de voz √© dividido em fragmentos de 10 milisegundos, o espectro de pot√™ncia* de cada fragmento √© mapeado para um vetor de n√∫meros reais conhecido como coeficientes cepstrais. A dimens√£o desse vetor √© pequena e a sa√≠da final do HMM √© uma sequ√™ncia desses vetores. Para decodificar o que foi falado em texto, grupos desses vetores s√£o combinados com um ou mais fonemas e um algoritmo especial √© aplicado para determinar a palavra/frase mais prov√°vel produzida. Esses fonemas exige treinamento, j√° que um som varia de pessoa para pessoa.

Sugiro que voc√™s pesquisem mais a fundo sobre esse modelo para entender como os c√°lculos e os treinamentos s√£o feitos. A boa not√≠cia para o *pythonista* √© que para tudo na vida hoje em dia tem biblioteca.Hoje existem v√°rios servi√ßos de reconhecimento de voz dispon√≠veis por meio de API, e n√≥s usaremos o **SpeechRecognition**.

## SpeechRecognition
SpeechRecognition √© um recurso importante usado na automa√ß√£o residencial e em dispositivos de intelig√™ncia artificial. 
A principal fun√ß√£o desta biblioteca √© fazer o que explicamos ali em cima: tentar entender tudo o que os humanos falam e converter a fala em texto.
A flexibilidade e facilidade de uso do pacote, o tornam uma escolha excelente para qualquer projeto Python. 

### Instalando 
```
pip install SpeechRecognition
```
No nosso caso vamos precisar instalar tamb√©m o PyAudio para capturarmos a entrada do microfone.

## Criando a Chica
Na assistente acoplei um nlp para identificar a inten√ß√£o do usu√°rio, eu expliquei [como fazer um bot usando aprendizado profundo](https://dev.to/thaisribeiro/como-criar-um-bot-usando-deep-learning-e-python-2d55) aqui no dev.to e l√° no medium, √© importante voc√™s lerem para entender como nosso modelo √© treinado e como s√£o classificadas as inten√ß√µes.
Supondo que temos nosso modelo treinado e nossas inten√ß√µes definidas, vamos criar nosso arquivo principal que ser√° o cara respons√°vel por capturar a voz do seu microfone e identificar o que voc√™ quis dizer, a explica√ß√£o est√° comentada no c√≥digo.

```python
import os
import pathlib
import random
import pytz
import speech_recognition as sr
import wikipedia
import pyjokes
from datetime import datetime, timezone
from speech import to_speak
from nlp.extract import get_response, class_prediction
from pydub import AudioSegment
from pydub.playback import play
from youtube import run_youtube

wikipedia.set_lang("pt")
path = pathlib.Path(__file__).parent.resolve()
IST = pytz.timezone('America/Sao_Paulo')

listener = sr.Recognizer()


def listening():
    # captura o som do microfone
    with sr.Microphone() as src:
        print('listening...')
        listener.adjust_for_ambient_noise(src)
        voice = listener.listen(src)
        try:
            event = listener.recognize_google(voice, language='pt-BR')
            event = event.lower()
        except:
            event = 'anything_else'

    return event


def voice_chica(tag):
    song = AudioSegment.from_mp3(f'{path}/audios/{tag}.mp3')
    play(song)

def run():
    """
        M√©todo que ir√° iniciar nossa assistente virtual e o reconhecimento de voz
        nesse momento a voz da chica ser√° o default.
        Quem enjoar da minha voz, pode usar o
        to_speak passando o random.choices(response) no lugar de voice_chica

    """
    event = listening()
    # retorna a voz transcrita, que foi falada ao microfone
    print(f'evento: {event}')
    
    # √© enviado para a classe de predi√ß√£o, para identificar as inten√ß√µes e assim buscar a resposta mais coerente se existir, caso n√£o exista cai no fallback.
Esse processo de NLP foi explicado no outro artigo.
    intents = class_prediction(event)
    response, context, tag = get_response(intents)

    if tag == 'song':
        voice_chica(tag)
        run_youtube(event)
    elif tag == 'hours':
        voice_chica(tag)
        hours_speak = f'{datetime.now(IST).hour} horas e {datetime.now(IST).minute} minutos'
        to_speak(hours_speak)
        voice_chica(f'{tag}2')
    elif tag == 'days':
        voice_chica(tag)
        days_speak = f'{datetime.now(IST).day}'
        to_speak(days_speak)
    elif tag == 'search':
        voice_chica(tag)
        voice_chica(f'{tag}2')
        info = wikipedia.summary(event, 1)
        to_speak(info)
    else:
        # voice_chica √© um m√©todo que ir√° reproduzir os √°udios com a minha voz haha e to_speak com a voz do google.
        voice_chica(tag)

while True:
    run()

```
Esse foi um exemplo de como ficou a classe principal, o projeto √© open source e est√° no meu [reposit√≥rio](https://github.com/thaisribeiro/chica).
Bom, vou deixar voc√™s colocarem a m√£o na massa e executarem o c√≥digo, assim como tentar entend√™-lo tamb√©m haha, vou ficando por aqui, espero que tenham gostado e pe√ßo gentilmente que leve esse e os outros artigos aos seus amigos, assim voc√™ estar√° compartilhando informa√ß√£o e incentivando o meu trabalho.
At√© mais.